{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d091c36",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b4d2d",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79cb0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer['data']\n",
    "y = cancer['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4401adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7ed9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2',knn2), ('lr',lr),('dt3',dt3),('dt5',dt5)])\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2',knn2), ('lr',lr),('dt3',dt3),('dt5',dt5)], voting= 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2f09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy:98.12%\n",
      "hard Test Accuracy:95.10%\n",
      "\n",
      "soft Train Accuracy:99.53%\n",
      "soft Test Accuracy:95.80%\n",
      "\n",
      "knn1 Train Accuracy:94.60%\n",
      "knn1 Test Accuracy:91.61%\n",
      "\n",
      "knn2 Train Accuracy:95.77%\n",
      "knn2 Test Accuracy:91.61%\n",
      "\n",
      "lr Train Accuracy:96.71%\n",
      "lr Test Accuracy:93.71%\n",
      "\n",
      "dt3 Train Accuracy:97.65%\n",
      "dt3 Test Accuracy:93.01%\n",
      "\n",
      "dt5 Train Accuracy:100.00%\n",
      "dt5 Test Accuracy:91.61%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = 'hard,soft,knn1,knn2,lr,dt3,dt5'.split(sep=\",\")\n",
    "\n",
    "for idx, model in enumerate([hard,soft,knn1,knn2,lr,dt3,dt5]):\n",
    "    model.fit(X_train,y_train)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(X_train, y_train)*100\n",
    "    test_score = model.score(X_test,y_test)*100\n",
    "    print(f'{name} Train Accuracy:{train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy:{test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17187150",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1b68f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9976525821596244, 0.951048951048951)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(X_train,y_train)\n",
    "model.score(X_train,y_train),model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36076d2f",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d477088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "model.score(X_train,y_train), model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f05419",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ee3cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()), ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators = estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "model.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb54aa",
   "metadata": {},
   "source": [
    "### Self Study - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a7d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X=digits['data']\n",
    "y=digits['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87ce49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8ef94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9910913140311804, 0.9888888888888889)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X,y)\n",
    "print(knn.score(X_train,y_train), knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd97f324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9644444444444444)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000).fit(X_train,y_train)\n",
    "print(lr.score(X_train,y_train), lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81c6c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47438752783964366, 0.4688888888888889)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)\n",
    "print(dt.score(X_train,y_train), dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "124d4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr1 = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74a5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2',knn2), ('lr1',lr1),('dt3',dt3),('dt5',dt5)])\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2',knn2), ('lr1',lr1),('dt3',dt3),('dt5',dt5)], voting= 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c17a1721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy:99.48%\n",
      "hard Test Accuracy:98.22%\n",
      "\n",
      "soft Train Accuracy:99.63%\n",
      "soft Test Accuracy:97.78%\n",
      "\n",
      "knn1 Train Accuracy:99.11%\n",
      "knn1 Test Accuracy:98.00%\n",
      "\n",
      "knn2 Train Accuracy:99.11%\n",
      "knn2 Test Accuracy:98.67%\n",
      "\n",
      "lr1 Train Accuracy:100.00%\n",
      "lr1 Test Accuracy:96.44%\n",
      "\n",
      "dt3 Train Accuracy:47.44%\n",
      "dt3 Test Accuracy:46.89%\n",
      "\n",
      "dt5 Train Accuracy:70.08%\n",
      "dt5 Test Accuracy:67.56%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = 'hard,soft,knn1,knn2,lr1,dt3,dt5'.split(sep=\",\")\n",
    "\n",
    "for idx, model in enumerate([hard,soft,knn1,knn2,lr1,dt3,dt5]):\n",
    "    model.fit(X_train,y_train)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(X_train, y_train)*100\n",
    "    test_score = model.score(X_test,y_test)*100\n",
    "    print(f'{name} Train Accuracy:{train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy:{test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "573a6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e+02 96.88888888888889\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "print(gb.score(X_train,y_train)*100, gb.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2817e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.73348181143281 94.88888888888889\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=5).fit(X_train,y_train)\n",
    "print(rf.score(X_train,y_train)*100,rf.score(X_test,y_test) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4daa094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.711111111111111e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()), ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "stack = StackingClassifier(estimators = estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "print(stack.fit(X_train,y_train).score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b756c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "best_model = {}\n",
    "\n",
    "# 데이터 분할\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(digits['data'],\n",
    "                                                    digits['target'],\n",
    "                                                    stratify=digits['target'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "# 모델 설정\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)], voting='soft')\n",
    "\n",
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    best_model[name] = [test_score]\n",
    "    \n",
    "# bagging\n",
    "for i in range(1, 6):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(max_depth=i).fit(x_tr, y_tr)\n",
    "    best_model[f'bagging, max_depth={i}'] = [model.score(x_te, y_te)]\n",
    "    \n",
    "# boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_tr, y_tr)\n",
    "best_model['boosting'] = [model.score(x_te, y_te)]\n",
    "\n",
    "# stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "             ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression())\n",
    "\n",
    "best_model['stacking'] = [model.fit(x_tr, y_tr).score(x_te, y_te)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8979d128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98.666667\n",
       "Name: knn2, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_model_df = pd.DataFrame(best_model).T\n",
    "best_model_df.sort_values(0, ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43bcdc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0\n",
      "hard                  98.222222\n",
      "soft                  97.777778\n",
      "knn1                  98.000000\n",
      "knn2                  98.666667\n",
      "lr                    96.444444\n",
      "dt3                   46.888889\n",
      "dt5                   67.777778\n",
      "bagging, max_depth=1   0.733333\n",
      "bagging, max_depth=2   0.824444\n",
      "bagging, max_depth=3   0.877778\n",
      "bagging, max_depth=4   0.924444\n",
      "bagging, max_depth=5   0.944444\n",
      "boosting               0.968889\n",
      "stacking               0.971111\n",
      "                   index          0\n",
      "0                   knn2  98.666667\n",
      "1                   hard  98.222222\n",
      "2                   knn1  98.000000\n",
      "3                   soft  97.777778\n",
      "4                     lr  96.444444\n",
      "5                    dt5  67.777778\n",
      "6                    dt3  46.888889\n",
      "7               stacking   0.971111\n",
      "8               boosting   0.968889\n",
      "9   bagging, max_depth=5   0.944444\n",
      "10  bagging, max_depth=4   0.924444\n",
      "11  bagging, max_depth=3   0.877778\n",
      "12  bagging, max_depth=2   0.824444\n",
      "13  bagging, max_depth=1   0.733333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'knn2'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_model_df = pd.DataFrame(best_model).T\n",
    "print(best_model_df)\n",
    "print(best_model_df.sort_values(0, ascending=False).reset_index())\n",
    "best_model_df.sort_values(0, ascending=False).reset_index().loc[0,\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b172c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#조익준\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "# 모델이름을 키로 성능점수를 저장한다\n",
    "# 나중에 데이터프레임으로 저장하기위해 사전타입에 저장한다.\n",
    "# 성능점수를 배열로 저장해야 데이터프레임으로 변환이 가능하다.\n",
    "best_model = {}  \n",
    "\n",
    "# 데이터 분할\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(digits['data'],\n",
    "                                                    digits['target'],\n",
    "                                                    stratify=digits['target'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "# 모델 설정\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)], voting='soft')\n",
    "\n",
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    best_model[name] = [test_score] # 성능점수를 배열로 저장한다\n",
    "    \n",
    "# bagging\n",
    "for i in range(1, 6):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(max_depth=i).fit(x_tr, y_tr)\n",
    "    best_model[f'bagging, max_depth={i}'] = [model.score(x_te, y_te)] # 성능점수를 배열로 저장한다\n",
    "    \n",
    "# boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_tr, y_tr)\n",
    "best_model['boosting'] = [model.score(x_te, y_te)] # 성능점수를 배열로 저장한다\n",
    "\n",
    "# stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "             ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression())\n",
    "\n",
    "best_model['stacking'] = [model.fit(x_tr, y_tr).score(x_te, y_te)] # 성능점수를 배열로 저장한다\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(best_model) # 가로로 긴 모양이 생성된다. 정렬하려면 세로로 길어야한다.\n",
    "best_model_df = pd.DataFrame(best_model).T # 가로를 세로로 변환한다.\n",
    "print(best_model_df)\n",
    "#0 칼럼기준 내림차순 정렬. 접근이 쉽도록 인덱스를 일반칼럼으로 변환하고 인덱스는 숫자로 새로 만들어준다.\n",
    "print(best_model_df.sort_values(0, ascending=False).reset_index()) \n",
    "# 맨 첫번째 행, \"index\"칼럼이 가장 성능좋은 모델이름이다.\n",
    "best_model_df.sort_values(0, ascending=False).reset_index().loc[0,\"index\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
